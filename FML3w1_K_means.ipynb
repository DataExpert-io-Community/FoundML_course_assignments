{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IP_K_means_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Aw1Vg-id4wS"
      },
      "source": [
        "# K-means Tutorial\n",
        "\n",
        "This project aims to introduce you to clustering through the K-means algorithm. This algorithm identifies clusters in data by continuously computing the mean of the closest data points. In this project we use a variant of this algorithm called mini batch K-means. The variation functions similarly to the standard K-means algorithm, but works on smaller batches of data from the entire dataset to compute the clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXQv8Bd6e9t_"
      },
      "source": [
        "# Import the necessary libraries\n",
        "import sklearn.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioOMKI1hK4mv"
      },
      "source": [
        "# Define some constants for plotting\n",
        "COLORS = [\"red\", \"green\", \"blue\", \"yellow\", \"purple\", \"cyan\", \"black\"]\n",
        "CLUSTER_COLORS = [\"magenta\", \"cyan\", \"black\", \"lime\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3i4m5xVf1C6"
      },
      "source": [
        "## Generate data\n",
        "\n",
        "Generate some data via the sklearn library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAa4AY9-Ddra"
      },
      "source": [
        "# We can generate a dataset with the following method\n",
        "X, y = datasets.make_blobs(100)\n",
        "\n",
        "# Set the size of the plot (width and height)\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Scatter all points in the dataset (Transpose the dataset to make the columns\n",
        "#  correspond to the x and y coordinates respectively)\n",
        "plt.scatter(X.T[0], X.T[1], s=25, color = COLORS[0])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL2MaKnAgE2Z"
      },
      "source": [
        "## Plotting method\n",
        "\n",
        "For clustering models on two dimensional data, it is often useful to plot the data visually to see how the data has been clustered, the method below does this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abaR9TnhLsyk"
      },
      "source": [
        "# We want to display the clustering once the model is fit to the data\n",
        "def plot_model_prediction(model, X, plt_w = 12, plt_h = 5):\n",
        "\n",
        "  # Get prediction from the model for all data points\n",
        "  preds = model.predict(X)\n",
        "\n",
        "  # Set plot size\n",
        "  plt.figure(figsize=(plt_w, plt_h))\n",
        "\n",
        "  # For every unique cluster generated by the model\n",
        "  for label in np.unique(preds):\n",
        "\n",
        "    # Take all the data points in the cluster 'label'\n",
        "    category = X[preds == label]\n",
        "\n",
        "    # Plot them with a new color\n",
        "    plt.scatter(category.T[0], category.T[1], s=25, color = COLORS[label])\n",
        "\n",
        "  # Plot the clusters centers \n",
        "  for i, cluster in enumerate(model.cluster_centers_):\n",
        "    plt.scatter(cluster[0], cluster[1], s=100, color = CLUSTER_COLORS[i])\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXlxcT1mglF9"
      },
      "source": [
        "## Use the algorithm\n",
        "\n",
        "The algorithm is easily imported and used, for more information regarding the avalable functionality of the model, look at the source: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysj2zdpBEBGO"
      },
      "source": [
        "# Import the MiniBatchKMeans method/algorithm\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "# Construct the model.\n",
        "# The batch_size defines how many data points are taken in one iteration.\n",
        "# Set batch_size to 1 to get the online K-means algorithm.\n",
        "# Set the n_clusters parameter to the desired number of clusters.\n",
        "model = MiniBatchKMeans(n_clusters= 3, batch_size=1)\n",
        "\n",
        "# Fit the model on the training dataset X.\n",
        "model.fit(X)\n",
        "\n",
        "#Plot the clusters found by the model in the training dataset X.\n",
        "plot_model_prediction(model, X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXiCaVcchhSv"
      },
      "source": [
        "## Algorithm results on different datasets\n",
        "\n",
        "Here we test the algorithm trained on several different datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kps22Sf7EGQH"
      },
      "source": [
        "# Create a collection of diferent datasets\n",
        "\n",
        "size = 500\n",
        "data_collection = [datasets.make_circles(size, noise = 0.1),\n",
        "                   datasets.make_moons(size, noise = 0.1),\n",
        "                   datasets.make_blobs(size),\n",
        "                   datasets.make_blobs(size)\n",
        "                   ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fshez64vHEKd"
      },
      "source": [
        "# Create one mini batck K-means model for each dataset, train it, and plot the clusters it found\n",
        "# Suggestion: try the algorithm with different numbers of clusters. \n",
        "\n",
        "for (X, y) in data_collection:\n",
        "  model = MiniBatchKMeans(n_clusters= 3, batch_size=1)\n",
        "  model.fit(X)\n",
        "  plot_model_prediction(model, X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtF_Z67RVjO4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI1eoJ5ogXX8"
      },
      "source": [
        "# K-means Project: identify the people in a set of images taken of their faces in different setups. \n",
        "\n",
        "In this project you will use the K-means algorithm to work on a set of images of human faces. We work with the Olivetti dataset, that contains a set of face images taken between April 1992 and April 1994 at the AT&T Laboratories Cambridge. There are ten different images of each of 40 distinct subjects. For some subjects, the images were taken at different times, varying the lighting, facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). All the images were taken against a dark homogeneous background with the subjects in an upright, frontal position (with tolerance for some side movement). The image is quantized to 256 grey levels and stored as unsigned 8-bit integers; the loader will convert these to floating point values on the interval [0, 1], which are easier to work with for many algorithms. The original dataset consisted of 92 x 112 sized images, while the version available here consists of 64x64 images.\n",
        "\n",
        "Your task is to attempt reconstruction the 40 people and show their headshot picture assembled on the basis of their 10 different pictures. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXGr68Udcxzd"
      },
      "source": [
        "SEED = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSBHAMXGz95N"
      },
      "source": [
        "# Load the \"Olivetti\" faces dataset. \n",
        "# Do not modify the parameters of the load function!!!\n",
        "faces = datasets.fetch_olivetti_faces(shuffle=True, random_state=SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_5ij0JbDsmN"
      },
      "source": [
        "# The number of pictures in the dataset\n",
        "faces.data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZF_Ykzw2kd_"
      },
      "source": [
        "## Explore the data\n",
        "\n",
        "Let's visualize the 400 pictures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V1lZZZ7HJI8"
      },
      "source": [
        "#Creating 40X10 subplots\n",
        "\n",
        "nrows=40\n",
        "ncols=10\n",
        "\n",
        "fig, axarr=plt.subplots(nrows, ncols, figsize=(18, 90))\n",
        "  \n",
        "#For easy iteration flattened 40X10 subplots matrix to 40 array\n",
        "axarr=axarr.flatten()\n",
        "    \n",
        "#iterating over \n",
        "\n",
        "for i in range(nrows):\n",
        "  for j in range(ncols):\n",
        "    index=i*ncols+j\n",
        "    axarr[index].imshow(faces[\"data\"][index].reshape(64, 64))\n",
        "    axarr[index].set_xticks([])\n",
        "    axarr[index].set_yticks([])\n",
        "    axarr[index].set_title(\"face id:{}\".format(index))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec31oCe13dt3"
      },
      "source": [
        "## Train the model and present results\n",
        "\n",
        "Let's train an online K-means model with a single cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzfBn8-YFh8Y"
      },
      "source": [
        "model = MiniBatchKMeans(n_clusters= 1, batch_size=1, random_state=SEED)\n",
        "model.fit(faces.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrNxHnJzSaFR"
      },
      "source": [
        "Let's visualize the center of the resulting cluster, interpreted as an image representing all the pictures in the cluster (i.e., all the pictures in the Olivetti dataset). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icyn0wlUcA-T"
      },
      "source": [
        "model.cluster_centers_.shape\n",
        "plt.imshow(model.cluster_centers_.reshape(64, 64))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN8OJFjUSvXg"
      },
      "source": [
        "Just to compare: let's calculate the mean of all the pictures in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "795FIaStdWS1"
      },
      "source": [
        "# Mean of the pixel poistions\n",
        "print(\"This is what the mean of all pictures in the dataset looks like:\")\n",
        "plt.imshow(np.mean(faces[\"data\"], axis = 0).reshape(64, 64))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2nJSO3pS6cJ"
      },
      "source": [
        "##Your task: train an online K-means algorithm with the suitable number of clusters to identify the individuals in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFjMO2DTTG5R"
      },
      "source": [
        "###Q1. How many clusters do you use?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1btdFL144MsY"
      },
      "source": [
        "# Write your code here\n",
        "# Set the random_state parameter in the model initialization to constant SEED (for verifiability purposes)\n",
        "\n",
        "...\n",
        "\n",
        "\n",
        "# Use the code below to visualize the centers of the clusters\n",
        "# Choose yourself the number of rows and columns in the visualization of the result\n",
        "\n",
        "nrows=4\n",
        "ncols=10\n",
        "fig, axarr=plt.subplots(nrows, ncols, figsize=(18, 9))\n",
        "  \n",
        "#For easy iteration flatten the matrix of pictures\n",
        "axarr=axarr.flatten()\n",
        "    \n",
        "#iterating over \n",
        "\n",
        "for i in range(nrows):\n",
        "  for j in range(ncols):\n",
        "    index=i*ncols+j\n",
        "    axarr[index].imshow(model.cluster_centers_[index].reshape(64, 64))\n",
        "    axarr[index].set_xticks([])\n",
        "    axarr[index].set_yticks([])\n",
        "    axarr[index].set_title(\"face id:{}\".format(index))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm1KR5XkTyf7"
      },
      "source": [
        "###Q2. The subject with \"face id: 10\" in the result: is it a man or a woman?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztwutAGQT-PM"
      },
      "source": [
        "###Q3. The subject with \"face id: 5\" in the result: does he/she wear glasses?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2gJrKsFUHgs"
      },
      "source": [
        "###Q4. Re-run the model with a different shuffling of the pictures (done in the load function). Are the pictures you got the same (even if in a different order)? In other words, is the algorithm robust to the order of the pictures in the dataset?"
      ]
    }
  ]
}