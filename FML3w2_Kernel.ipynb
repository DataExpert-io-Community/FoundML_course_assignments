{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IP_Kernel_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x-OLsZ5Jqfs"
      },
      "source": [
        "# Kernels Tutorial\n",
        "\n",
        "Support vector machines (SVM) are classification models which base their decisions on the kernel type. In this project we use the SVM model within the sklearn library. The documentation for this library is available at https://scikit-learn.org/stable/modules/svm.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HuQhRzvnHv8"
      },
      "source": [
        "# Original Code source: Gaël Varoquaux & Andreas Müller\n",
        "# Modified for documentation by Jaques Grobler\n",
        "# Edited for course project by Joel Sjöberg and Ion Petre\n",
        "# License: BSD 3 clause\n",
        "\n",
        "# Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "# For data standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Import the support vector classifier \n",
        "from sklearn.svm import SVC\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_R51IEQgCtU"
      },
      "source": [
        "import random\n",
        "\n",
        "random.seed(2021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS175ovknY5M"
      },
      "source": [
        "We will see how the kernels are used to form decision boundaries for a simple dataset. We will use the \"make_moons\" method for generating a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAbTIehEnXrj"
      },
      "source": [
        "# Generate dataset\n",
        "X, y = make_moons(noise=0.2, random_state=0,  n_samples = 1000)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Create an instance of the standardization scaler\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "# Standardize the training data to mean 0 and standard deviation 1.\n",
        "# We get this through fitting the scaler to the training data.\n",
        "X_train = std_scaler.fit_transform(X_train)\n",
        "\n",
        "# Use the same scaler to transform the test data. \n",
        "# This is needed because the model will be trained on standardized data.\n",
        "# Even for novel \"production\" data, we will have to apply the same standardization.\n",
        "# Note that the scaler isn't fit again on the test data!!\n",
        "X_test = std_scaler.transform(X_test)\n",
        "\n",
        "# Scatter the training points according to their category\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=30, cmap=plt.cm.Paired)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yhe-lwowD5o"
      },
      "source": [
        "## Creating a model\n",
        "\n",
        "We now create a model to categorize the dataset. We begin with a linear kernel model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnmup7RYD6bu"
      },
      "source": [
        "# Import the support vector classifier \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Fit a linear support vector classifier\n",
        "clf = SVC(kernel=\"linear\", C=1.0, random_state = 0)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Measure accuracy on the train data\n",
        "print(\"Accuracy on the training set:\", clf.score(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMrxM5f5Exju"
      },
      "source": [
        "# Plot the decision boundary and the support vectors\n",
        "\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=30, cmap=plt.cm.Paired)\n",
        "\n",
        "# plot the decision function\n",
        "ax = plt.gca()\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "\n",
        "# create grid to evaluate model\n",
        "xx = np.linspace(xlim[0], xlim[1], 30)\n",
        "yy = np.linspace(ylim[0], ylim[1], 30)\n",
        "YY, XX = np.meshgrid(yy, xx)\n",
        "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "Z = clf.decision_function(xy).reshape(XX.shape)\n",
        "\n",
        "# plot decision boundary and margins\n",
        "ax.contour(\n",
        "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
        ")\n",
        "# plot support vectors\n",
        "ax.scatter(\n",
        "    clf.support_vectors_[:, 0],\n",
        "    clf.support_vectors_[:, 1],\n",
        "    s=100,\n",
        "    linewidth=1,\n",
        "    facecolors=\"none\",\n",
        "    edgecolors=\"k\",\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpT4DY-n5XZW"
      },
      "source": [
        "Let's try now a polynomial kernel. We will get better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTIWfjlT5WfG"
      },
      "source": [
        "# Initialize model\n",
        "# Suggestion: try several different degrees in the kernel by modifying the parameter \"degree\"\n",
        "pol_model = SVC(kernel=\"poly\", degree=3, C=1.0, random_state = 0)\n",
        "\n",
        "# Train the model\n",
        "pol_model.fit(X_train, y_train)\n",
        "\n",
        "# Measure accuracy on the training data\n",
        "print(\"Accuracy on the training set:\", pol_model.score(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo3_J7_IIzpD"
      },
      "source": [
        "# Plot the decision boundary and the support vectors\n",
        "\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=30, cmap=plt.cm.Paired)\n",
        "\n",
        "# plot the decision function\n",
        "ax = plt.gca()\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "\n",
        "# create grid to evaluate model\n",
        "xx = np.linspace(xlim[0], xlim[1], 30)\n",
        "yy = np.linspace(ylim[0], ylim[1], 30)\n",
        "YY, XX = np.meshgrid(yy, xx)\n",
        "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "Z = pol_model.decision_function(xy).reshape(XX.shape)\n",
        "\n",
        "# plot decision boundary and margins\n",
        "ax.contour(\n",
        "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
        ")\n",
        "# plot support vectors\n",
        "ax.scatter(\n",
        "    pol_model.support_vectors_[:, 0],\n",
        "    pol_model.support_vectors_[:, 1],\n",
        "    s=100,\n",
        "    linewidth=1,\n",
        "    facecolors=\"none\",\n",
        "    edgecolors=\"k\",\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kstXR36SL3P"
      },
      "source": [
        "Let's try now the Radial Basis Function kernel (RBF). We will get even better results (which was to be expected, given the elyptic distribution of the datapoints)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMX1iV6m58Fo"
      },
      "source": [
        "# Initialize model\n",
        "rbf_model = SVC(kernel=\"rbf\", C=1.0, gamma = 2, random_state = 0)\n",
        "\n",
        "# Train the model\n",
        "rbf_model.fit(X_train, y_train)\n",
        "\n",
        "# Measure accuracy on the training data\n",
        "print(\"Accuracy on the training set:\", rbf_model.score(X_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0ZhRwPRJwKK"
      },
      "source": [
        "# Plot the decision boundary and the support vectors\n",
        "\n",
        "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=30, cmap=plt.cm.Paired)\n",
        "\n",
        "# plot the decision function\n",
        "ax = plt.gca()\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "\n",
        "# create grid to evaluate model\n",
        "xx = np.linspace(xlim[0], xlim[1], 30)\n",
        "yy = np.linspace(ylim[0], ylim[1], 30)\n",
        "YY, XX = np.meshgrid(yy, xx)\n",
        "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
        "Z = rbf_model.decision_function(xy).reshape(XX.shape)\n",
        "\n",
        "# plot decision boundary and margins\n",
        "ax.contour(\n",
        "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
        ")\n",
        "# plot support vectors\n",
        "ax.scatter(\n",
        "    rbf_model.support_vectors_[:, 0],\n",
        "    rbf_model.support_vectors_[:, 1],\n",
        "    s=100,\n",
        "    linewidth=1,\n",
        "    facecolors=\"none\",\n",
        "    edgecolors=\"k\",\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0otdsrh45NN"
      },
      "source": [
        "Conclusion: the RBF kernel is the best in this example, the decision boundary follows the data quite faithfully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWNxzO5sJu8o"
      },
      "source": [
        "# Kernels Project\n",
        "\n",
        "Let's load a simple income dataset. Each data point is an individual with various features such as age, education, marital status, native country, number of work hours per week, etc. The target value is 1 if the person earns 50k per year or more, 0 otherwise. The dataset is available in the Penn Machine Learning Benchmarks library. Information about this collection can be found at https://github.com/EpistasisLab/pmlb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXejdmCNOnrm"
      },
      "source": [
        "# Install the pmlb library on this runtime\n",
        "!pip install pmlb\n",
        "import pmlb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSebwFfQt_nn"
      },
      "source": [
        "Link to dataset metadata (feature descriptions) : https://github.com/EpistasisLab/pmlb/blob/master/datasets/adult/metadata.yaml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWjYHeSNPIWs"
      },
      "source": [
        "#import pandas as pd\n",
        "#pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Get the \"adult\" dataset\n",
        "frame = pmlb.fetch_data(\"adult\")\n",
        "\n",
        "# Print the head of the resulting dataframe\n",
        "print(frame.head(10))\n",
        "\n",
        "# Print the name of the features in the data\n",
        "print(frame.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBpI9oZE16iC"
      },
      "source": [
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        frame.to_numpy()[:, :-1], frame.to_numpy()[:, -1], test_size=0.3, random_state=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5meqUdhB6S9"
      },
      "source": [
        "## Modelling\n",
        "\n",
        "Let's build a support vector machine model separating the individuals with respect to whether they may over 50k/year. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaT40lB8f149"
      },
      "source": [
        "random.seed(2021)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MV0fSWitpa1"
      },
      "source": [
        "# Try the linear kernel\n",
        "# Q1: What is the accuracy on the training dataset? Use random_state = 0.\n",
        "\n",
        "# Initialize model\n",
        "\n",
        "# Train the model\n",
        "\n",
        "# Measure accuracy on the training data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhDHOG8xOMmx"
      },
      "source": [
        "# Try the polynomial kernel\n",
        "# Q2: What is the best fitting polynomial kernel between degrees 1, 2, 3, 4, 5. \n",
        "# Use random_state = 0.\n",
        "\n",
        "random.seed(2021)\n",
        "\n",
        "\n",
        "\n",
        "# Q3. For the best fitting polynomial kernel, what is the accuracy on the training dataset?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IafEr0UbONmT"
      },
      "source": [
        "# Try the RBF kernel\n",
        "# Q4: What is the accuracy on the training dataset? Use random_state = 0.\n",
        "\n",
        "random.seed(2021)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "\n",
        "\n",
        "# Measure accuracy on the training data\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKEqnrJpPlwW"
      },
      "source": [
        "# Q5. For the model with the best accuracy on the training dataset, what is its accuracy on the test dataset?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IJ3h2QRnNPy"
      },
      "source": [
        "# Measure accuracy on the test data\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}